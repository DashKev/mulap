# Configuration for training
training:
  # Name of the trainer class used to define the training/evalution loop
  trainer: base_trainer
  # Experiment id to use in logging and checkpoints
  experiment_id: null
  # Maximum number of epochs
  epochs: 100
  # Device on which the model will be trained. Set 'cpu' to train/infer on CPU
  device: cuda

  # Configuration for data loading 
  # Size of each batch
  batch_size: 64
  # Number of workers to be used in dataloader
  num_workers: 4
  # Whether to shuffle in dataloader
  shuffle: true
  # Whether to pin memory in dataloader
  pin_memory: true
  # Whether gradients should be clipped
  
  # Configuration for optimizer
  optimizer: adamw
  # Epsilson for Adam optimizer
  adam_epsilon: 1e-8
  # Betas for Adam
  adam_betas: [0.9, 0.98]
  # Weight decay for Adam
  weight_decay: 0.01
  # Warmup steps as a proportion of total training steps
  warmup_proportion: 0.1
  # Initial learning rate
  lr: 0.0001
  grad_acc_steps: 1
  # Whether to use mixed precision training instead of full precision (FP32)
  amp: true
  # Early stopping configs
  early_stop:
    # Whether to use early stopping, (Default: false)
    enabled: false
    # Patience for early stoppings
    patience: 4000
    # Criteria to be monitored for early stopping
    criteria: loss
    # Whether the monitored criteria should be minimized for early stopping
    minimize: true
    
# Environment configuration
env:
  # Base directory of the repo, populated when config is loaded
  base_dir: null
  # Directory for storing datasets and models
  data_root: ${env.base_dir}/data
  # Directory for experiments, logs, output samples etc.
  save_dir: ${env.base_dir}/save
  # Directory for saving models, logs and checkpoints for each experiment
  experiments_dir: ${env.save_dir}/experiments
  # Directory for saving logs, default is inside the save folder
  log_dir: ${env.experiments_dir}/${training.experiment_id}/logs
